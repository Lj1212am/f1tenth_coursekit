.. _doc_lab9:


Lab 9 - Robot Ethics
=================================
.. note:: This is a **INDIVIDUAL** assignment.

.. tip:: Be prepared for the dicussion to come in :ref:`Lecture 22 <doc_lecture22>`

| **Goals:**
| As engineers, we design systems to have a certain function: move parts in a warehouse, interpret and implement a surgeonâ€™s hand movements, or drive passengers around. Aside from functionality, we also design safety, security and reliability into our systems. With autonomous systems, we will be asked to design *ethics* into our systems, since they will share the world with us and make decisions autonomously, and some of these decisions are bound to involve ethical questions. How can we design and program an autonomous system that is ethical? Indeed, what does it mean for an autonomous system to be ethical? Or even, just responsible for its actions? Are there certain autonomous systems that simply cannot be ethical? Moreover, when speaking about designing ethical systems, *whose ethics are we talking about*?

| **Learning Outcomes:**
| This assignment asks us to discuss some of the ethical considerations inherent in the design of autonomous systems generally, not just self-driving cars. It is divided into three parts, which ask the following:

	#. Who or what is morally responsible for the decisions made by an autonomous system? 
	#. How can responsibility be programmed?
	#. How do context and function affect the question of designing ethical behavior?


**Allotted Time:** 1.5 week

| **Repository:** `Github Repository <https://github.com/f1tenth/f1tenth_labs/tree/master/lab9/handout>`_ 
|	The repository contains the latex source files as well as any skeleton code. Compile the latex source files to view the most up to date handout.

.. raw:: html

	<iframe width="700" height="800" src="https://drive.google.com/file/d/1AL1bzESlr2J4qepXvTl5kfp3c2qoI9d9/view?usp=drive_link" width="640" height="480"></iframe>